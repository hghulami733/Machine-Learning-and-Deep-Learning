{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFMJwMNCTlc6",
        "outputId": "7f1da218-0d4e-4482-9fab-d55722983379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from patchify) (1.25.2)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDAYOszeb2eZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from math import log2\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Dense, Dropout, Input, ReLU, Reshape,\n",
        "                                        BatchNormalization, MaxPool2D, Embedding,\n",
        "                                        LayerNormalization, MultiHeadAttention,\n",
        "                                        Activation, Add, Concatenate, Conv2D,\n",
        "                                        Conv2DTranspose)\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint, CSVLogger, ReduceLROnPlateau,\n",
        "                                        EarlyStopping)\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from patchify import patchify\n",
        "from tensorflow.keras.models import Model, load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "# Open the tar file\n",
        "with tarfile.open('/content/drive/MyDrive/LaPa.tar.gz', 'r:gz') as tar:\n",
        "    # Extract all contents to the current directory\n",
        "    tar.extractall()\n"
      ],
      "metadata": {
        "id": "WPlrgbYCll4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf = {}\n",
        "cf[\"image_size\"] = 256\n",
        "cf[\"num_classes\"] = 11\n",
        "cf[\"num_layers\"] = 12\n",
        "cf[\"hidden_dim\"] = 128\n",
        "cf[\"mlp_dim\"] = 32\n",
        "cf[\"num_heads\"] = 6\n",
        "cf[\"dropout_rate\"] = 0.1\n",
        "cf[\"patch_size\"] = 16\n",
        "cf[\"num_patches\"] = (cf[\"image_size\"]**2)//(cf[\"patch_size\"]**2)\n",
        "cf[\"num_channels\"] = 3\n",
        "cf[\"flat_patches_shape\"] = (\n",
        "    cf[\"num_patches\"],\n",
        "    cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"]\n",
        ")"
      ],
      "metadata": {
        "id": "fgioCG-xb6XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "metadata": {
        "id": "nshRfqNtb6Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path):\n",
        "    X_train = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.jpg\")))\n",
        "    y_train = sorted(glob(os.path.join(path, \"train\", \"labels\", \"*.png\")))\n",
        "\n",
        "    X_val = sorted(glob(os.path.join(path, \"val\", \"images\", \"*.jpg\")))\n",
        "    y_val = sorted(glob(os.path.join(path, \"val\", \"labels\", \"*.png\")))\n",
        "\n",
        "    X_test = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.jpg\")))\n",
        "    y_test = sorted(glob(os.path.join(path, \"test\", \"labels\", \"*.png\")))\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)"
      ],
      "metadata": {
        "id": "ZtRC53nAb6aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, cf):\n",
        "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    x = Dense(cf[\"hidden_dim\"])(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "kleHh7E8b6ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(x, cf):\n",
        "    skip_1 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = MultiHeadAttention(\n",
        "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
        "    )(x, x)\n",
        "    x = Add()([x, skip_1])\n",
        "\n",
        "    skip_2 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = mlp(x, cf)\n",
        "    x = Add()([x, skip_2])\n",
        "    return x"
      ],
      "metadata": {
        "id": "_m9Nm4iPb6c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(x, num_filters, kernel_size=3):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "dSkpMAPKb6fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deconv_block(x, num_filters, strides=2):\n",
        "    x = Conv2DTranspose(num_filters, kernel_size=2, padding=\"same\", strides=strides)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ygQB1ekNb6hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unetr_2d(cf):\n",
        "    input_sahpe = (cf[\"num_patches\"], cf[\"patch_size\"] * cf[\"patch_size\"] * cf[\"num_channels\"])\n",
        "    inputs = Input(input_sahpe)\n",
        "\n",
        "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)\n",
        "\n",
        "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
        "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions)\n",
        "    x = patch_embed + pos_embed\n",
        "\n",
        "    skip_connection_index = [3, 6, 9, 12]\n",
        "    skip_connections = []\n",
        "\n",
        "    for i in range(1, cf[\"num_layers\"] + 1, 1):\n",
        "        x = transformer_encoder(x, cf)\n",
        "\n",
        "        if i in skip_connection_index:\n",
        "            skip_connections.append(x)\n",
        "\n",
        "    z3, z6, z9, z12 = skip_connections\n",
        "\n",
        "    z0 = Reshape((cf[\"image_size\"], cf[\"image_size\"], cf[\"num_channels\"]))(inputs)\n",
        "\n",
        "    shape = (\n",
        "        cf[\"image_size\"] // cf[\"patch_size\"],\n",
        "        cf[\"image_size\"] // cf[\"patch_size\"],\n",
        "        cf[\"hidden_dim\"]\n",
        "    )\n",
        "\n",
        "    z3 = Reshape(shape)(z3)\n",
        "    z6 = Reshape(shape)(z6)\n",
        "    z9 = Reshape(shape)(z9)\n",
        "    z12 = Reshape(shape)(z12)\n",
        "\n",
        "    total_upsampe_factor = int(log2(cf[\"patch_size\"]))\n",
        "    upscale = total_upsampe_factor - 4\n",
        "    #  print(upscale)\n",
        "\n",
        "    if upscale >= 1:\n",
        "        z3 = deconv_block(z3, z3.shape[-1], strides=2**upscale)\n",
        "        z6 = deconv_block(z6, z6.shape[-1], strides=2**upscale)\n",
        "        z9 = deconv_block(z9, z9.shape[-1], strides=2**upscale)\n",
        "        z12 = deconv_block(z12, z12.shape[-1], strides=2**upscale)\n",
        "\n",
        "    if upscale < 0:\n",
        "        p = 2 **abs(upscale)\n",
        "        z3 = MaxPool2D((p, p))(z3)\n",
        "        z6 = MaxPool2D((p, p))(z6)\n",
        "        z9 = MaxPool2D((p, p))(z9)\n",
        "        z12 = MaxPool2D((p, p))(z12)\n",
        "\n",
        "    x = deconv_block(z12, 128)\n",
        "\n",
        "    s = deconv_block(z9, 128)\n",
        "    s = conv_block(s, 128)\n",
        "\n",
        "    x = Concatenate()([x, s])\n",
        "\n",
        "    x = conv_block(x, 128)\n",
        "    x = conv_block(x, 128)\n",
        "\n",
        "    x = deconv_block(x, 64)\n",
        "\n",
        "    s = deconv_block(z6, 64)\n",
        "    s = conv_block(s, 64)\n",
        "    s = deconv_block(s, 64)\n",
        "    s = conv_block(s, 64)\n",
        "\n",
        "    x = Concatenate()([x, s])\n",
        "    x = conv_block(x, 64)\n",
        "    x = conv_block(x, 64)\n",
        "\n",
        "    x = deconv_block(x, 32)\n",
        "\n",
        "    s = deconv_block(z3, 32)\n",
        "    s = conv_block(s, 32)\n",
        "    s = deconv_block(s, 32)\n",
        "    s = conv_block(s, 32)\n",
        "    s = deconv_block(s, 32)\n",
        "    s = conv_block(s, 32)\n",
        "\n",
        "    x = Concatenate()([x, s])\n",
        "    x = conv_block(x, 32)\n",
        "    x = conv_block(x, 32)\n",
        "\n",
        "    x = deconv_block(x, 16)\n",
        "\n",
        "    s = conv_block(z0, 16)\n",
        "    s = conv_block(s, 16)\n",
        "\n",
        "    x = Concatenate()([x, s])\n",
        "    x = conv_block(x, 16)\n",
        "    x = conv_block(x, 16)\n",
        "\n",
        "    outputs = Conv2D(cf[\"num_classes\"], kernel_size=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
        "\n",
        "    return Model(inputs, outputs, name=\"UNETR_2D\")"
      ],
      "metadata": {
        "id": "MvMO6Z23b6iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "\n",
        "    config = {}\n",
        "    config[\"image_size\"] = 256\n",
        "    config[\"num_classes\"] = 11\n",
        "    config[\"num_layers\"] = 12\n",
        "    config[\"hidden_dim\"] = 64\n",
        "    config[\"mlp_dim\"] = 128\n",
        "    config[\"num_heads\"] = 6\n",
        "    config[\"dropout_rate\"] = 0.1\n",
        "    config[\"patch_size\"] = 16\n",
        "    config[\"num_patches\"] = (config[\"image_size\"]**2)//(config[\"patch_size\"]**2)\n",
        "    config[\"num_channels\"] = 3\n",
        "\n",
        "    model = build_unetr_2d(config)\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbUAxSbBb6kU",
        "outputId": "d217920a-c6a0-4562-b1b2-42089b6a3ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNETR_2D\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 768)]           0         []                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256, 64)              49216     ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 256, 64)              0         ['dense[0][0]']               \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, 256, 64)              128       ['tf.__operators__.add[0][0]']\n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, 256, 64)              99520     ['layer_normalization[0][0]', \n",
            " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 256, 64)              0         ['multi_head_attention[0][0]',\n",
            "                                                                     'tf.__operators__.add[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 256, 64)              128       ['add[0][0]']                 \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 256, 128)             8320      ['layer_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 256, 128)             0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 256, 64)              8256      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 256, 64)              0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 256, 64)              0         ['dropout_1[0][0]',           \n",
            "                                                                     'add[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 256, 64)              128       ['add_1[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 256, 64)              99520     ['layer_normalization_2[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 256, 64)              0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_1[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 256, 64)              128       ['add_2[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256, 128)             8320      ['layer_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 256, 128)             0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 256, 64)              8256      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 256, 64)              0         ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 256, 64)              0         ['dropout_3[0][0]',           \n",
            "                                                                     'add_2[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 256, 64)              128       ['add_3[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 256, 64)              99520     ['layer_normalization_4[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 256, 64)              0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_3[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, 256, 64)              128       ['add_4[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 256, 128)             8320      ['layer_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 256, 128)             0         ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 256, 64)              8256      ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 256, 64)              0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 256, 64)              0         ['dropout_5[0][0]',           \n",
            "                                                                     'add_4[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_6 (Lay  (None, 256, 64)              128       ['add_5[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, 256, 64)              99520     ['layer_normalization_6[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_6[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 256, 64)              0         ['multi_head_attention_3[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_5[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_7 (Lay  (None, 256, 64)              128       ['add_6[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 256, 128)             8320      ['layer_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 256, 128)             0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 256, 64)              8256      ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 256, 64)              0         ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 256, 64)              0         ['dropout_7[0][0]',           \n",
            "                                                                     'add_6[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_8 (Lay  (None, 256, 64)              128       ['add_7[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (Mu  (None, 256, 64)              99520     ['layer_normalization_8[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 256, 64)              0         ['multi_head_attention_4[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_7[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_9 (Lay  (None, 256, 64)              128       ['add_8[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 256, 128)             8320      ['layer_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 256, 128)             0         ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 256, 64)              8256      ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 256, 64)              0         ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 256, 64)              0         ['dropout_9[0][0]',           \n",
            "                                                                     'add_8[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_10 (La  (None, 256, 64)              128       ['add_9[0][0]']               \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (Mu  (None, 256, 64)              99520     ['layer_normalization_10[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 256, 64)              0         ['multi_head_attention_5[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_9[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_11 (La  (None, 256, 64)              128       ['add_10[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 256, 128)             8320      ['layer_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 256, 128)             0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 256, 64)              8256      ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 256, 64)              0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 256, 64)              0         ['dropout_11[0][0]',          \n",
            "                                                                     'add_10[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_12 (La  (None, 256, 64)              128       ['add_11[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (Mu  (None, 256, 64)              99520     ['layer_normalization_12[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 256, 64)              0         ['multi_head_attention_6[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_11[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_13 (La  (None, 256, 64)              128       ['add_12[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 256, 128)             8320      ['layer_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 256, 128)             0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 256, 64)              8256      ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 256, 64)              0         ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 256, 64)              0         ['dropout_13[0][0]',          \n",
            "                                                                     'add_12[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_14 (La  (None, 256, 64)              128       ['add_13[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (Mu  (None, 256, 64)              99520     ['layer_normalization_14[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 256, 64)              0         ['multi_head_attention_7[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_13[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_15 (La  (None, 256, 64)              128       ['add_14[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 256, 128)             8320      ['layer_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 256, 128)             0         ['dense_15[0][0]']            \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 256, 64)              8256      ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 256, 64)              0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " add_15 (Add)                (None, 256, 64)              0         ['dropout_15[0][0]',          \n",
            "                                                                     'add_14[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_16 (La  (None, 256, 64)              128       ['add_15[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_8 (Mu  (None, 256, 64)              99520     ['layer_normalization_16[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_16 (Add)                (None, 256, 64)              0         ['multi_head_attention_8[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_15[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_17 (La  (None, 256, 64)              128       ['add_16[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 256, 128)             8320      ['layer_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)        (None, 256, 128)             0         ['dense_17[0][0]']            \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 256, 64)              8256      ['dropout_16[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)        (None, 256, 64)              0         ['dense_18[0][0]']            \n",
            "                                                                                                  \n",
            " add_17 (Add)                (None, 256, 64)              0         ['dropout_17[0][0]',          \n",
            "                                                                     'add_16[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_18 (La  (None, 256, 64)              128       ['add_17[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_9 (Mu  (None, 256, 64)              99520     ['layer_normalization_18[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_18 (Add)                (None, 256, 64)              0         ['multi_head_attention_9[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_17[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_19 (La  (None, 256, 64)              128       ['add_18[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 256, 128)             8320      ['layer_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)        (None, 256, 128)             0         ['dense_19[0][0]']            \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 256, 64)              8256      ['dropout_18[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)        (None, 256, 64)              0         ['dense_20[0][0]']            \n",
            "                                                                                                  \n",
            " add_19 (Add)                (None, 256, 64)              0         ['dropout_19[0][0]',          \n",
            "                                                                     'add_18[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_20 (La  (None, 256, 64)              128       ['add_19[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_10 (M  (None, 256, 64)              99520     ['layer_normalization_20[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_20 (Add)                (None, 256, 64)              0         ['multi_head_attention_10[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_19[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_21 (La  (None, 256, 64)              128       ['add_20[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_21 (Dense)            (None, 256, 128)             8320      ['layer_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)        (None, 256, 128)             0         ['dense_21[0][0]']            \n",
            "                                                                                                  \n",
            " dense_22 (Dense)            (None, 256, 64)              8256      ['dropout_20[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)        (None, 256, 64)              0         ['dense_22[0][0]']            \n",
            "                                                                                                  \n",
            " add_21 (Add)                (None, 256, 64)              0         ['dropout_21[0][0]',          \n",
            "                                                                     'add_20[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_22 (La  (None, 256, 64)              128       ['add_21[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_11 (M  (None, 256, 64)              99520     ['layer_normalization_22[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_22 (Add)                (None, 256, 64)              0         ['multi_head_attention_11[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_21[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_23 (La  (None, 256, 64)              128       ['add_22[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_23 (Dense)            (None, 256, 128)             8320      ['layer_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)        (None, 256, 128)             0         ['dense_23[0][0]']            \n",
            "                                                                                                  \n",
            " dense_24 (Dense)            (None, 256, 64)              8256      ['dropout_22[0][0]']          \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)         (None, 16, 16, 64)           0         ['add_17[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)        (None, 256, 64)              0         ['dense_24[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 32, 32, 128)          32896     ['reshape_3[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " add_23 (Add)                (None, 256, 64)              0         ['dropout_23[0][0]',          \n",
            "                                                                     'add_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 128)          147584    ['conv2d_transpose_1[0][0]']  \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)         (None, 16, 16, 64)           0         ['add_23[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 32, 32, 128)          512       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 32, 32, 128)          32896     ['reshape_4[0][0]']           \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 32, 32, 128)          0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 16, 16, 64)           0         ['add_11[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 32, 32, 256)          0         ['conv2d_transpose[0][0]',    \n",
            "                                                                     're_lu[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 32, 32, 64)           16448     ['reshape_2[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 128)          295040    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 64)           36928     ['conv2d_transpose_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 128)          512       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 64)           256       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 32, 32, 128)          0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 32, 32, 64)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 16, 16, 64)           0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 128)          147584    ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 64, 64, 64)           16448     ['re_lu_3[0][0]']             \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2D  (None, 32, 32, 32)           8224      ['reshape_1[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 128)          512       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d_transpose_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)           9248      ['conv2d_transpose_6[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 32, 32, 128)          0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 64, 64, 64)           256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 32)           128       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 64, 64, 64)           32832     ['re_lu_2[0][0]']             \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 64, 64, 64)           0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)              (None, 32, 32, 32)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_transpose_2[0][0]',  \n",
            " )                                                                   're_lu_4[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2D  (None, 64, 64, 32)           4128      ['re_lu_7[0][0]']             \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 64)           73792     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 64, 64, 32)           9248      ['conv2d_transpose_7[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 64, 64, 64)           256       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 64, 64, 32)           128       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 64, 64, 64)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 64, 64, 32)           0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 64)           36928     ['re_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2D  (None, 128, 128, 32)         4128      ['re_lu_8[0][0]']             \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 64, 64, 64)           256       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 128, 128, 32)         9248      ['conv2d_transpose_8[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)              (None, 64, 64, 64)           0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 128, 128, 32)         128       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 128, 128, 32)         8224      ['re_lu_6[0][0]']             \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 128, 128, 32)         0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 128, 128, 64)         0         ['conv2d_transpose_5[0][0]',  \n",
            " )                                                                   're_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 128, 128, 32)         18464     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 256, 256, 3)          0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 128, 128, 32)         128       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 256, 256, 16)         448       ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)             (None, 128, 128, 32)         0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 256, 256, 16)         64        ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 128, 128, 32)         9248      ['re_lu_10[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)             (None, 256, 256, 16)         0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 128, 128, 32)         128       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 256, 256, 16)         2320      ['re_lu_12[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)             (None, 128, 128, 32)         0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 256, 256, 16)         64        ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_9 (Conv2D  (None, 256, 256, 16)         2064      ['re_lu_11[0][0]']            \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)             (None, 256, 256, 16)         0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 256, 256, 32)         0         ['conv2d_transpose_9[0][0]',  \n",
            " )                                                                   're_lu_13[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 256, 256, 16)         4624      ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 256, 256, 16)         64        ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)             (None, 256, 256, 16)         0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 256, 256, 16)         2320      ['re_lu_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 256, 256, 16)         64        ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)             (None, 256, 256, 16)         0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 256, 256, 11)         187       ['re_lu_15[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2447323 (9.34 MB)\n",
            "Trainable params: 2445595 (9.33 MB)\n",
            "Non-trainable params: 1728 (6.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
        "    image = image / 255.0\n",
        "\n",
        "    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
        "    patches = patchify(image, patch_shape, cf[\"patch_size\"])\n",
        "    patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
        "    patches = patches.astype(np.float32)\n",
        "\n",
        "    return patches"
      ],
      "metadata": {
        "id": "ryxjVN2Rb6nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
        "    mask = mask.astype(np.int32)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "tEa7Ck4hb6pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_parse(x, y):\n",
        "    def parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        y = tf.one_hot(y, cf[\"num_classes\"])\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape(cf[\"flat_patches_shape\"])\n",
        "    y.set_shape([cf[\"image_size\"], cf[\"image_size\"], cf[\"num_classes\"]])\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "Ulq5Hut-b6sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_dataset(X, Y, batch=2):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    ds = ds.map(tf_parse).batch(batch).prefetch(10)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "IMof7OLMb6vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "    dataset_path = \"/content/LaPa\"\n",
        "\n",
        "    #create_dir(\"/content/drive/MyDrive/Data\" + \"/filesa\")\n",
        "\n",
        "    batch_size = 8\n",
        "    learning_rate = 0.001\n",
        "    num_epochs = 15\n",
        "    model_path = os.path.join(\"/content/drive/MyDrive/Data\" + \"/files\", \"Multiclass_segmentation_using_UNETR_50_Epochs_model.h5\") # epoches till now is 39\n",
        "    csv_path = os.path.join(\"/content/drive/MyDrive/Data\" + \"/files\", \"Multiclass_segmentation_using_UNETR_50_Epochs_log.csv\")\n",
        "\n",
        "    rgb_codes = [\n",
        "        [0, 0, 0], [0, 153, 255], [102, 255, 153], [0, 204, 153],\n",
        "        [255, 255, 102], [255, 255, 204], [255, 153, 0], [255, 102, 255],\n",
        "        [102, 0, 51], [255, 204, 255], [255, 0, 102]\n",
        "    ]\n",
        "\n",
        "    classes = [\n",
        "        \"background\", \"skin\", \"left eyebrow\", \"right eyebrow\",\n",
        "        \"left eye\", \"right eye\", \"nose\", \"upper lip\", \"inner mouth\",\n",
        "        \"lower lip\", \"hair\"\n",
        "    ]\n",
        "\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_dataset(dataset_path)\n",
        "    print(f\"Trianing : \\t{len(X_train)} - {len(y_train)}\")\n",
        "    print(f\"Validation : \\t{len(X_val)} - {len(y_val)}\")\n",
        "    print(f\"Test : \\t{len(X_test)} - {len(y_test)}\")\n",
        "\n",
        "    train_dataset = tf_dataset(X_train, y_train, batch=batch_size)\n",
        "    val_dataset = tf_dataset(X_val, y_val, batch=batch_size)\n",
        "\n",
        "    #model = build_unetr_2d(cf)\n",
        "    model = load_model(\"/content/drive/MyDrive/Data/files/Multiclass_segmentation_using_UNETR_48_Epochs_model.h5\", compile=False)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(learning_rate=learning_rate))\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, varbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=False)\n",
        "    ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxaV-Nz_b6yK",
        "outputId": "ba98ac3b-f20d-42af-f77f-3c2f984b2e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trianing : \t18168 - 18168\n",
            "Validation : \t2000 - 2000\n",
            "Test : \t2000 - 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N2Lz5SwR8zQ",
        "outputId": "bb008ff6-6d24-444b-e53c-1d5efa2974bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "2271/2271 [==============================] - 545s 228ms/step - loss: 0.1635 - val_loss: 0.2550 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "2271/2271 [==============================] - 514s 226ms/step - loss: 0.1628 - val_loss: 0.2524 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "2271/2271 [==============================] - 519s 229ms/step - loss: 0.1630 - val_loss: 0.2510 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "2271/2271 [==============================] - 525s 231ms/step - loss: 0.1626 - val_loss: 0.2504 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "2271/2271 [==============================] - 562s 247ms/step - loss: 0.1622 - val_loss: 0.2505 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "2271/2271 [==============================] - 515s 227ms/step - loss: 0.1618 - val_loss: 0.2505 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "2271/2271 [==============================] - 516s 227ms/step - loss: 0.1615 - val_loss: 0.2503 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "1739/2271 [=====================>........] - ETA: 1:56 - loss: 0.1706"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_results(image, mask, pred, save_path):\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    mask = grayscale_to_rgb(mask, rgb_codes)\n",
        "\n",
        "    pred = np.expand_dims(pred, axis=-1)\n",
        "    pred = grayscale_to_rgb(pred, rgb_codes)\n",
        "\n",
        "    line = np.ones((image.shape[0], 10, 3)) * 255\n",
        "\n",
        "    cat_images = np.concatenate([image, line, mask, line, pred], axis=1)\n",
        "    cv2.imwrite(save_image_path, cat_images)"
      ],
      "metadata": {
        "id": "K6FHGVGYb66i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    create_dir(dataset_path + \"/results\")\n",
        "\n",
        "    model_path = os.path.join(dataset_path, \"/files\", \"Multiclass_segmentation_using_UNETR_500_Epochs_model.h5\")\n",
        "    csv_path = os.path.join(dataset_path, \"/files\", \"Multiclass_segmentation_using_UNETR_500_Epochs_log.csv\")\n",
        "\n",
        "    rgb_codes = [\n",
        "        [0, 0, 0], [0, 153, 255], [102, 255, 153], [0, 204, 153],\n",
        "        [255, 255, 102], [255, 255, 204], [255, 153, 0], [255, 102, 255],\n",
        "        [102, 0, 51], [255, 204, 255], [255, 0, 102]\n",
        "    ]\n",
        "\n",
        "    classes = [\n",
        "        \"background\", \"skin\", \"left eyebrow\", \"right eyebrow\",\n",
        "        \"left eye\", \"right eye\", \"nose\", \"upper lip\", \"inner mouth\",\n",
        "        \"lower lip\", \"hair\"\n",
        "    ]\n",
        "\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_dataset(dataset_path)\n",
        "    print(f\"Trianing : \\t{len(X_train)} - {len(y_train)}\")\n",
        "    print(f\"Validation : \\t{len(X_val)} - {len(y_val)}\")\n",
        "    print(f\"Test : \\t{len(X_test)} - {len(y_test)}\")\n",
        "\n",
        "    for x, y in tqdm(zip(X_test, y_test), total=len(X_test)):\n",
        "        print(x, y)\n",
        "\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "        image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
        "        x = image / 255.0\n",
        "\n",
        "        patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
        "        patches = patchify(x, patch_shape, cf[\"patch_size\"])\n",
        "        patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
        "        patches = patches.astype(np.float32)\n",
        "        patches = np.expand_dims(patches, axis=0)\n",
        "\n",
        "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
        "        mask = mask.astype(np.int32)\n",
        "\n",
        "        pred = model.predict(patches, verbose=0)[0]\n",
        "        print(pred.shape)\n",
        "        pred = np.argmax(pred, axis=-1)\n",
        "        pred = pred.astype(np.int32)\n",
        "\n",
        "        save_image_path = dataset_path + f\"/results/{name}.png\"\n",
        "        save_results(image, mask, pred, save_image_path)"
      ],
      "metadata": {
        "id": "aIrOsmEjb67H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}