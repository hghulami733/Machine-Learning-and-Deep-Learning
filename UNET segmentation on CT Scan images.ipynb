{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ed3328fa-c460-4c3b-bd34-de7a0c8c3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "import pydicom as dicom\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score, accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.metrics import Recall, Precision, IoU\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda4ad7a-53b2-415a-92fa-fc5b99d127d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 512\n",
    "W = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306be2d0-5c99-4435-af0b-36ca9fd03c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "778ceb31-aa19-499d-a5b8-bd2eac4834d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path, split=0.2):\n",
    "    images = sorted(glob(f\"{dataset_path}\\\\*\\\\image\\\\*.png\"))\n",
    "    masks = sorted(glob(f\"{dataset_path}\\\\*\\\\mask\\\\*.png\"))\n",
    "    print(len(images), len(masks))\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    X_train, X_val = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    y_train, y_val = train_test_split(masks, test_size=split_size, random_state=42)\n",
    "\n",
    "    print(\"Training : \", len(X_train), len(y_train))\n",
    "    print(\"Validation : \", len(X_val), len(y_val))\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e38bfde-b112-4657-b208-588b3bf96ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_data(images, masks, save_path, augment=True):\n",
    "\n",
    "    H = 512\n",
    "    W = 512\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        #print(x)\n",
    "        #print(y)\n",
    "\n",
    "        dir_name = x.split(\"\\\\\")[-3]\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        full_name = dir_name + \"_\" + name\n",
    "        #print(dir_name)\n",
    "        #print(name)\n",
    "        #print(full_name)\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y = cv2.imread(y, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment == True:\n",
    "            aug = HorizontalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1 = augmented[\"image\"]\n",
    "            y1 = augmented[\"mask\"]\n",
    "\n",
    "            aug = VerticalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x2 = augmented[\"image\"]\n",
    "            y2 = augmented[\"mask\"]\n",
    "\n",
    "            aug = Rotate(limit=45, p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x3 = augmented[\"image\"]\n",
    "            y3 = augmented[\"mask\"]\n",
    "\n",
    "            X = [x, x1, x2, x3]\n",
    "            y = [y, y1, y2, y3]\n",
    "\n",
    "        else:\n",
    "            X = [x]\n",
    "            y = [y]\n",
    "\n",
    "        index = 0\n",
    "        for i, m in zip(X, y):\n",
    "            i = cv2.resize(i, (W, H))\n",
    "            m = cv2.resize(m, (W, H))\n",
    "            m = m / 255.0\n",
    "            m = (m > 0.5) * 255\n",
    "\n",
    "            if len(X) == 1:\n",
    "                tmp_image_name = f\"{full_name}.jpg\"\n",
    "                tmp_mask_name = f\"{full_name}.jpg\"\n",
    "\n",
    "            else:\n",
    "                tmp_image_name = f\"{full_name}_{index}.jpg\"\n",
    "                tmp_mask_name = f\"{full_name}_{index}.jpg\"\n",
    "\n",
    "            image_path = os.path.join(save_path, \"images\\\\\", tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, \"masks\\\\\", tmp_mask_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "                \n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68cdd827-88ea-4381-83da-d7d0044feeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2532 2532\n",
      "Training :  2026 2026\n",
      "Validation :  506 506\n",
      "train :  2026\n",
      "validataion :  506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2026/2026 [02:00<00:00, 16.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 506/506 [00:06<00:00, 73.36it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    dataset_path = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data/\"\n",
    "    dataset = os.path.join(dataset_path, \"train\")\n",
    "    (X_train, y_train), (X_val, y_val) = load_data(dataset, split=0.2)\n",
    "    print(\"train : \", len(X_train))\n",
    "    print(\"validataion : \", len(X_val))\n",
    "\n",
    "    create_dir(dataset_path + \"new_data/train/images\")\n",
    "    create_dir(dataset_path + \"new_data/train/masks\")\n",
    "    create_dir(dataset_path + \"new_data/val/images\")\n",
    "    create_dir(dataset_path + \"new_data/val/masks\")\n",
    "\n",
    "    save_path_train = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\\new_data\\train\"\n",
    "    save_path_test = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\\new_data\\val\"\n",
    "\n",
    "    augmentation_data(X_train, y_train, save_path_train, augment=True)\n",
    "    augmentation_data(X_val, y_val, save_path_test, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b81d2c6e-c700-4e71-81ef-4d861076a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "994c67a5-83f6-486a-aed0-edd1a05053fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6a7dac4-b9d7-42a9-badc-613c27c2bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(input, skip_feature, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_feature])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb8c466d-9450-435d-91be-7673f3ece8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b = conv_block(p4, 1024)\n",
    "\n",
    "    d1 = decoder_block(b, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"Unet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40d32065-35d1-448a-bc89-294612eb4cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hamid\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hamid\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"Unet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 512, 512, 64)         1792      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 512, 512, 64)         256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 512, 512, 64)         0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 512, 512, 64)         36928     ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 512, 512, 64)         256       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 512, 512, 64)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 256, 256, 64)         0         ['activation_1[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 256, 256, 128)        73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 256, 256, 128)        512       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 256, 256, 128)        0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 128)        147584    ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 256, 256, 128)        512       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 256, 256, 128)        0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 128, 128, 128)        0         ['activation_3[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 256)        295168    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 128, 128, 256)        1024      ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 128, 128, 256)        0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 256)        590080    ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 128, 128, 256)        1024      ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 128, 128, 256)        0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 64, 64, 256)          0         ['activation_5[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 64, 64, 512)          2048      ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 64, 64, 512)          0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 512)          2359808   ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 64, 64, 512)          2048      ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 64, 64, 512)          0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 32, 32, 512)          0         ['activation_7[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 32, 32, 1024)         4096      ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 32, 32, 1024)         0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 1024)         9438208   ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 32, 32, 1024)         4096      ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 32, 32, 1024)         0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 64, 64, 512)          2097664   ['activation_9[0][0]']        \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64, 64, 1024)         0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 64, 64, 512)          4719104   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 64, 64, 512)          2048      ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 64, 64, 512)          2359808   ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 64, 64, 512)          2048      ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 128, 128, 256)        524544    ['activation_11[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 128, 128, 512)        0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 128, 128, 256)        1179904   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 128, 128, 256)        1024      ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 128, 128, 256)        590080    ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 128, 128, 256)        1024      ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 256, 256, 128)        131200    ['activation_13[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 256, 256, 256)        0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 256, 256, 128)        295040    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 256, 256, 128)        512       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 256, 256, 128)        147584    ['activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 256, 256, 128)        512       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 512, 512, 64)         32832     ['activation_15[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 512, 512, 128)        0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 512, 512, 64)         73792     ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 512, 512, 64)         256       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 512, 512, 64)         36928     ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 512, 512, 64)         256       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 512, 512, 1)          65        ['activation_17[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31055297 (118.47 MB)\n",
      "Trainable params: 31043521 (118.42 MB)\n",
      "Non-trainable params: 11776 (46.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    input_shape = (512, 512, 3)\n",
    "    model = build_unet(input_shape)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec6186db-54f5-47cb-8a94-85971b408737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "692b8951-810c-4e8c-a443-d65450ca625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1e-15\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = Flatten()(y_true)\n",
    "    y_pred = Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d63d929e-9075-4070-9d51-b2854e60bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "431e4abb-5a4d-4f2d-8477-90377af2f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffling(x, y):\n",
    "    x, y = shuffle(x, y, random_state=42)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a57209b2-0890-4b64-8a5b-7eae13097c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    x = sorted(glob(os.path.join(path, \"images\", \"*.jpg\")))\n",
    "    y = sorted(glob(os.path.join(path, \"masks\", \"*.jpg\")))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "49b2013d-e2b6-474c-84f7-0439f39eaedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    #x = cv2.resize(x, (W, H))\n",
    "    x = x / 255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1a2ce73f-a03b-433d-9381-cbb4f7340754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_masks(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    #x = cv2.resize(x, (W, H))\n",
    "    x = x / 255.0\n",
    "    x = x > 0.5\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "545f73f6-32c5-4ec4-9354-d12462517bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def parse(x, y):\n",
    "        x = read_images(x)\n",
    "        y = read_masks(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([H, W, 3])\n",
    "    y.set_shape([H, W, 1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "47f210dd-c5a5-45ac-ad1b-5ce0a933322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch=0):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    #dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(10)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2c8af-2cc1-405b-a389-a05b0073efdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ba82139d-c19f-4b72-b219-37a135b41c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 8108 - 8108\n",
      "Valid: 507 - 507\n",
      "1013/1013 [==============================] - ETA: 0s - loss: 0.7065 - dice_coef: 0.2935 - iou: 0.2101 - recall_8: 0.7865 - precision_8: 0.2302\n",
      "Epoch 1: val_loss improved from inf to 0.69781, saving model to E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\\files\\CT_Scan.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamid\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 9850s 10s/step - loss: 0.7065 - dice_coef: 0.2935 - iou: 0.2101 - recall_8: 0.7865 - precision_8: 0.2302 - val_loss: 0.6978 - val_dice_coef: 0.3022 - val_iou: 0.2065 - val_recall_8: 0.9837 - val_precision_8: 0.2505 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    save_model_path = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\"\n",
    "    create_dir(save_model_path + \"/files\")\n",
    "\n",
    "    batch_size = 2\n",
    "    learning_rate = 1e-4\n",
    "    num_epochs = 10\n",
    "    model_path = os.path.join(save_model_path , \"files\" , \"CT_Scan.h5\")\n",
    "    csv_path = os.path.join(save_model_path , \"files\" , \"CT_scan.csv\")\n",
    "\n",
    "    data = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\\new_data\"\n",
    "\n",
    "    train_path = os.path.join(data, \"train\")\n",
    "    \n",
    "    validation_path = os.path.join(data, \"val\")\n",
    "\n",
    "    X_train1, y_train1 = load_dataset(train_path)\n",
    "    X_train1, y_train1 = shuffling(X_train1, y_train1)\n",
    "    X_val1, y_val1 = load_dataset(validation_path)\n",
    "\n",
    "    print(f\"Training: {len(X_train1)} - {len(y_train1)}\")\n",
    "    print(f\"Valid: {len(X_val1)} - {len(y_val1)}\")\n",
    "\n",
    "    train_dataset = tf_dataset(X_train, y_train, batch=batch_size)\n",
    "    val_dataset = tf_dataset(X_val, y_val, batch=batch_size)\n",
    "\n",
    "    model = build_unet((H, W, 3))\n",
    "    metrics = [dice_coef, iou, Recall(), Precision()]\n",
    "    model.compile(loss=dice_loos, optimizer=Adam(learning_rate=learning_rate), metrics=metrics)\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=10, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        #TensorBoard(),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=50, restore_best_weights=False),\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1, #num_epochs,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "59b297d2-90c3-4337-bb35-4c084494ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Unet_segmentation_on_ct_scan.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f0d80601-6ff7-4b4b-b596-2a9599411a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(image, mask, y_pred, save_image_path):\n",
    "    line = np.ones((H, 10, 3)) * 255\n",
    "    \n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
    "\n",
    "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n",
    "    y_pred = y_pred * 255\n",
    "\n",
    "    #print(image.shape, mask.shape, y_pred.shape)\n",
    "    cat_images = np.concatenate([image, line, mask, y_pred], axis=1)\n",
    "    cv2.imwrite(save_image_path, cat_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a721bbfe-16a8-413b-bf7c-8010510802c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 507 - 507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/507 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:  1-090\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/507 [00:04<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    path = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\\files\"\n",
    "    create_dir(path + \"result\")\n",
    "    \n",
    "    my_model = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\\files\\CT_Scan.h5\"\n",
    "\n",
    "    with CustomObjectScope({\"dice_coef\":dice_coef, \"dice_loss\":dice_loos}):\n",
    "        loaded_model = tf.keras.models.load_model(my_model, compile=False)\n",
    "\n",
    "    #loaded_model.summary()\n",
    "    test_path = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\\new_data\"\n",
    "    X_test = sorted(glob(os.path.join(test_path, \"val\", \"images\", \"*\")))\n",
    "    y_test = sorted(glob(os.path.join(test_path, \"val\", \"masks\", \"*\")))\n",
    "    print(f\"Test: {len(X_test)} - {len(y_test)}\")\n",
    "\n",
    "    #(X_train, y_train_mask), (X_validation, y_validation_mask), (X_test, y_mask_test) = load_dataset(dataset)\n",
    "\n",
    "    score = []\n",
    "    for x, y in tqdm(zip(X_test, y_test), total=len(X_test)):\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        print(\"name: \", name)\n",
    "\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        #image = cv2.resize(image, (W, H))\n",
    "        x = image / 255.0\n",
    "        #x = x.astype(np.float32)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "        #mask = cv2.resize(mask, (W, H))\n",
    "        y = mask / 255.0\n",
    "        y = y > 0.5\n",
    "        y =y.astype(np.int32)\n",
    "                                \n",
    "        y_pred = loaded_model.predict(x)[0]\n",
    "        y_pred = np.squeeze(y_pred, axis=-1)\n",
    "        #print(y_pred.shape)\n",
    "        y_pred = y_pred >= 0.5\n",
    "        y_pred = y_pred.astype(np.int32)\n",
    "\n",
    "        save_image_path = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\\filesresult/\"\n",
    "        save_image = f\"{name}.png\"\n",
    "        save_image_path = os.path.join(save_image_path, save_image)\n",
    "        save_results(image, mask, y_pred, save_image_path)\n",
    "\n",
    "        y = y.Flatten()\n",
    "        y_pred = y_pred.Flatten()\n",
    "\n",
    "        acc_value = accuracy_score(y, y_pred)\n",
    "        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\", zero_division=1)\n",
    "        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\", zero_division=1)\n",
    "        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\", zero_division=1)\n",
    "        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\", zero_division=1)\n",
    "\n",
    "        score.append([name, acc_value ,f1_value, jac_value, recall_value, precision_value])\n",
    "    print(score)\n",
    "    score = [s[1:] for s in score]\n",
    "    score = np.mean(score, axis=0)\n",
    "    print(f\"Accuracy: {score[0]:0.5f}\")\n",
    "    print(f\"F1: {score[1]:0.5f}\")\n",
    "    print(f\"Jaccard: {score[2]:0.5f}\")\n",
    "    print(f\"Recall: {score[3]:0.5f}\")\n",
    "    print(f\"Precision: {score[4]:0.5f}\")\n",
    "\n",
    "    df = pf.DataFrame(score, columns=[\"Image\", \"Accuracy\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
    "    df.to_csv(\"files/score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "683dfad3-d292-4ff9-99e5-9398106ef67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/832 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 1)\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020EEC127240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/832 [00:04<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "test = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\"\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    create_dir(path + \"result\")\n",
    "    my_model = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\\files\\CT_Scan.h5\"\n",
    "\n",
    "    with CustomObjectScope({\"dice_coef\":dice_coef, \"dice_loss\":dice_loss}):\n",
    "        loaded_model = tf.keras.models.load_model(my_model, compile=False)\n",
    "\n",
    "    X_test = glob(test + \"\\\\test\\\\*\\\\*\\\\*.dcm\")\n",
    "    print(f\"Test: {len(X_test)}\")\n",
    "\n",
    "    for x in tqdm(X_test):\n",
    "        direc_name = x.split(\"\\\\\")[-3]\n",
    "        test_name = direc_name + \"_\" + x.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        image = dicom.dcmread(x).pixel_array\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        print(image.shape)\n",
    "        #print(np.max(image))\n",
    "\n",
    "        image = image / np.max(image) * 255.0\n",
    "        x = image / 255.0\n",
    "        x = np.concatenate([x, x, x], axis=-1)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        mask = loaded_model.predict(x)[0]\n",
    "        mask = mask > 0.5\n",
    "        mask = mask.astype(np.int32)\n",
    "        mask = mask * 255\n",
    "\n",
    "        cat_images = np.concatenate([image, mask], axis=1)\n",
    "        test_save = r\"E:\\python\\segmentation\\Computer Vision\\Data\\CTarchive\\data\"\n",
    "        test_save = os.path.join(test_save, \"files\")\n",
    "        cv2.imwrite(test_save + f\"\\\\{test_name}.png\", cat_images)\n",
    "\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fba118-2481-4954-91c7-2ec557d3a79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e4527-5718-473d-872d-445cbf98973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9250941e-e277-4787-8ada-23024bcb2779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbcc79-3291-4fbd-b17e-15856de19e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a437820-ef50-48c9-821e-2e8977cc163c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
