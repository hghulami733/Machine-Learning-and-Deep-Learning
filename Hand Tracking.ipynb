{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "399d3957-933e-426d-ac0a-339965bff631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "134493a1-f28d-4085-bd24-ba922cec87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r\"E:\\python\\segmentation\\Computer Vision\\Computer Vision\\Data\\Hand.mp4\")\n",
    "cap.set(3, 720)\n",
    "cap.set(4, 640)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "pre_time = 0\n",
    "curr_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff96b219-4815-48ef-8b2f-2e8395523ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "\n",
    "class Hand_detector():\n",
    "    def __init__(self, mode=False, max_hands=2, model_complexity=1, detection_conf=0.5, track_conf=0.5):\n",
    "        self.mode = mode\n",
    "        self.max_hands = max_hands\n",
    "        self.model_complexity = model_complexity\n",
    "        self.detection_conf = detection_conf\n",
    "        self.track_conf = track_conf\n",
    "        \n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(self.mode, self.max_hands, self.model_complexity,\n",
    "                                         self.detection_conf, self.track_conf)\n",
    "        self.mp_draw = mp.solutions.drawing_utils\n",
    "        self.tipIds = [4, 8, 12, 16, 20]\n",
    "\n",
    "    def find_hands(self, img, draw=True): \n",
    "\n",
    "        self.image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(self.image_rgb)\n",
    "        #print(results.multi_hand_landmarks)\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for hands_lms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                        \n",
    "                    self.mp_draw.draw_landmarks(img, hands_lms,\n",
    "                                                self.mp_hands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "\n",
    "    def find_position(self, img, hand_num=0, draw=True):\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        bbox = []\n",
    "        \n",
    "        self.landmark_list = []\n",
    "        \n",
    "        if self.results.multi_hand_landmarks:\n",
    "            my_hand = self.results.multi_hand_landmarks[hand_num]\n",
    "            \n",
    "            for id, lm in enumerate(my_hand.landmark):\n",
    "                #print(id, landmark)\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                x_list.append(cx)\n",
    "                y_list.append(cy)\n",
    "                #print(id, cx, cy)\n",
    "                self.landmark_list.append([id, cx, cy])\n",
    "                if draw:\n",
    "                    cv2.circle(img, (cx, cy), 5, (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "            x_min, x_max = min(x_list), max(x_list)\n",
    "            y_min, y_max = min(y_list), max(y_list)\n",
    "            bbox = x_min, y_min, x_max, y_max\n",
    "\n",
    "            if draw:\n",
    "                cv2.rectangle(img, (x_min - 20, y_min - 20), (x_max + 20, y_max + 20),\n",
    "                                 (0, 255, 0), 2)\n",
    "\n",
    "        return self.landmark_list, bbox\n",
    "\n",
    "    def finger_up(self):\n",
    "        fingers = []\n",
    "\n",
    "        # Thumb\n",
    "        if self.landmark_list[self.tipIds[0]][1] > self.landmark_list[self.tipIds[0] - 1][1]:\n",
    "            fingers.append(1)\n",
    "\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "        for id in range(1, 5):\n",
    "            if self.landmark_list[self.tipIds[id]][2] < self.landmark_list[self.tipIds[id] - 2][2]:\n",
    "                fingers.append(1)\n",
    "\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "        return fingers\n",
    "\n",
    "    def find_distance(self, p1, p2, img, draw=True, r=15, thickness=3):\n",
    "        x1, y1 = self.landmark_list[p1][1:]\n",
    "        x2, y2 = self.landmark_list[p2][1:]\n",
    "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "        if draw:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), thickness)\n",
    "            cv2.circle(img, (x1, y1), r, (0, 255, 0), cv2.FIELLD)\n",
    "            cv2.circle(img, (x2, y2), r, (0, 255, 0), cv2.FIELLD)\n",
    "            cv2.circle(img, (cx, cy), r, (0, 255, 0), cv2.FIELLD)\n",
    "\n",
    "        length = math.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        return length, img, [x1, y1, x2, y2, cx, cy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5980a0-343d-4859-b80e-110137eb9f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[ 78, 117, 102],\n",
      "        [ 77, 116, 101],\n",
      "        [ 78, 117, 102],\n",
      "        ...,\n",
      "        [ 68, 103,  88],\n",
      "        [ 68, 103,  88],\n",
      "        [ 64,  99,  84]],\n",
      "\n",
      "       [[ 78, 117, 102],\n",
      "        [ 77, 116, 101],\n",
      "        [ 78, 117, 102],\n",
      "        ...,\n",
      "        [ 67, 102,  87],\n",
      "        [ 67, 102,  87],\n",
      "        [ 66, 101,  86]],\n",
      "\n",
      "       [[ 74, 113,  98],\n",
      "        [ 74, 113,  98],\n",
      "        [ 79, 118, 103],\n",
      "        ...,\n",
      "        [ 66, 101,  86],\n",
      "        [ 66, 101,  86],\n",
      "        [ 67, 102,  87]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[102, 144, 128],\n",
      "        [104, 146, 130],\n",
      "        [105, 147, 131],\n",
      "        ...,\n",
      "        [ 91, 134, 114],\n",
      "        [ 90, 133, 113],\n",
      "        [ 86, 129, 109]],\n",
      "\n",
      "       [[102, 144, 128],\n",
      "        [105, 147, 131],\n",
      "        [106, 148, 132],\n",
      "        ...,\n",
      "        [ 88, 131, 111],\n",
      "        [ 86, 129, 109],\n",
      "        [ 89, 132, 112]],\n",
      "\n",
      "       [[102, 144, 128],\n",
      "        [105, 147, 131],\n",
      "        [107, 149, 133],\n",
      "        ...,\n",
      "        [ 83, 126, 106],\n",
      "        [ 79, 122, 102],\n",
      "        [ 81, 124, 104]]], dtype=uint8),)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m img \u001b[38;5;241m=\u001b[39m detectore\u001b[38;5;241m.\u001b[39mfind_hands(img),\u001b[38;5;66;03m#draw=False)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(img)\n\u001b[1;32m---> 12\u001b[0m landmark_list \u001b[38;5;241m=\u001b[39m detectore\u001b[38;5;241m.\u001b[39mfind_position(img)\u001b[38;5;66;03m#, draw=False)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(landmark_list) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(landmark_list[\u001b[38;5;241m4\u001b[39m])\n",
      "Cell \u001b[1;32mIn[5], line 45\u001b[0m, in \u001b[0;36mHand_detector.find_position\u001b[1;34m(self, img, hand_num, draw)\u001b[0m\n\u001b[0;32m     41\u001b[0m my_hand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks[hand_num]\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, lm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(my_hand\u001b[38;5;241m.\u001b[39mlandmark):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m#print(id, landmark)\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     h, w, c \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     46\u001b[0m     cx, cy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(lm\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m*\u001b[39m w), \u001b[38;5;28mint\u001b[39m(lm\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m*\u001b[39m h)\n\u001b[0;32m     47\u001b[0m     xl_list\u001b[38;5;241m.\u001b[39mappend(cx)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pre_time = 0\n",
    "    curr_time = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(r\"E:\\python\\segmentation\\Computer Vision\\Computer Vision\\Data\\Hand.mp4\")\n",
    "\n",
    "    detectore = Hand_detector()\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img = detectore.find_hands(img),#draw=False)\n",
    "        print(img)\n",
    "        landmark_list = detectore.find_position(img)#, draw=False)\n",
    "        if len(landmark_list) != 0:\n",
    "            print(landmark_list[4])\n",
    "        \n",
    "        curr_time = time.time()\n",
    "        fps = 1 / (curr_time - pre_time)\n",
    "        pre_time = curr_time\n",
    "    \n",
    "        cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN,\n",
    "                   3, (255, 255, 0), 2)\n",
    "    \n",
    "        cv2.imshow(\"image\", img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba209807-0306-48b1-af9a-0f38d9635375",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;241m720\u001b[39m, \u001b[38;5;241m720\u001b[39m))\n\u001b[0;32m     10\u001b[0m img \u001b[38;5;241m=\u001b[39m detectore\u001b[38;5;241m.\u001b[39mfind_hands(img)\n\u001b[1;32m---> 11\u001b[0m landmark_list \u001b[38;5;241m=\u001b[39m detectore\u001b[38;5;241m.\u001b[39mfind_position(img)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(landmark_list) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(landmark_list[\u001b[38;5;241m4\u001b[39m])\n",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m, in \u001b[0;36mHand_detector.find_position\u001b[1;34m(self, img, hand_num, draw)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m draw:\n\u001b[0;32m     50\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mcircle(img, (cx, cy), \u001b[38;5;241m15\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFILLED)\n\u001b[1;32m---> 52\u001b[0m x_min, x_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(xl_list), \u001b[38;5;28mmax\u001b[39m(xl_list)\n\u001b[0;32m     53\u001b[0m y_min, y_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(yl_list), \u001b[38;5;28mmax\u001b[39m(yl_list)\n\u001b[0;32m     54\u001b[0m bbox \u001b[38;5;241m=\u001b[39m xmin, x_max, y_min, y_max\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "pre_time = 0\n",
    "curr_time = 0\n",
    "\n",
    "cap = cv2.VideoCapture(r\"E:\\python\\segmentation\\Computer Vision\\Computer Vision\\Data\\Hand.mp4\")\n",
    "\n",
    "detectore = Hand_detector()\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.resize(img, (720, 720))\n",
    "    img = detectore.find_hands(img)\n",
    "    landmark_list = detectore.find_position(img)\n",
    "    if len(landmark_list) != 0:\n",
    "        print(landmark_list[4])\n",
    "        \n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - pre_time)\n",
    "    pre_time = curr_time\n",
    "    \n",
    "    cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN,\n",
    "                3, (255, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"image\", img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3feb7-0a7f-4fba-840b-bce092dd807d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
