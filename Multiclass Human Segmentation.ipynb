{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pt_WmYkSe1MU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hamid\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization,Flatten, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eep7OI2EfzPC"
   },
   "outputs": [],
   "source": [
    "global IMG_H\n",
    "global IMG_W\n",
    "global NUM_CLASSES\n",
    "global CLASSES\n",
    "global COLOR_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ki3tW9upgCh6"
   },
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "  if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "94HaS5-ue1O0"
   },
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "  x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "\n",
    "  x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONu5Xcr7gaeC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QJMzzRY-e1S3"
   },
   "outputs": [],
   "source": [
    "def encoder_block(input, num_filters):\n",
    "  x = conv_block(input, num_filters)\n",
    "  p = MaxPool2D((2, 2))(x)\n",
    "\n",
    "  return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bVGQ56BVevC0"
   },
   "outputs": [],
   "source": [
    "def decoder_block(input, skip_features, num_filters):\n",
    "  x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "  x = Concatenate()([x, skip_features])\n",
    "  x = conv_block(x, num_filters)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "v5NNJuu6evFr"
   },
   "outputs": [],
   "source": [
    "def build_unet(input_shape, num_classes):\n",
    "  inputs = Input(input_shape)\n",
    "\n",
    "  s1, p1 = encoder_block(inputs, 64)\n",
    "  s2, p2 = encoder_block(p1, 128)\n",
    "  s3, p3 = encoder_block(p2, 256)\n",
    "  s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "  b1 = conv_block(p4, 1024)\n",
    "\n",
    "  d1 = decoder_block(b1, s4, 512)\n",
    "  d2 = decoder_block(d1, s3, 256)\n",
    "  d3 = decoder_block(d2, s2, 128)\n",
    "  d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "  output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
    "\n",
    "  model = Model(inputs, output, name=\"U_Net\")\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCIpk5sxevIL",
    "outputId": "321b2d70-c6ea-4e8c-ee80-7b8fac676090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U_Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 512, 512, 64)         1792      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 512, 512, 64)         256       ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 512, 512, 64)         36928     ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 512, 512, 64)         256       ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 256, 256, 64)         0         ['activation_11[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 256, 256, 128)        73856     ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 256, 256, 128)        512       ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 256, 256, 128)        147584    ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 256, 256, 128)        512       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 128, 128, 128)        0         ['activation_13[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 128, 128, 256)        295168    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 128, 128, 256)        1024      ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 256)        590080    ['activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 128, 128, 256)        1024      ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 64, 64, 256)          0         ['activation_15[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 64, 64, 512)          1180160   ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 64, 64, 512)          2048      ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 64, 64, 512)          2359808   ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 64, 64, 512)          2048      ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 32, 32, 512)          0         ['activation_17[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 32, 32, 1024)         4719616   ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 32, 32, 1024)         4096      ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, 32, 32, 1024)         0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 32, 32, 1024)         9438208   ['activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 32, 32, 1024)         4096      ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, 32, 32, 1024)         0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 64, 64, 512)          2097664   ['activation_19[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 64, 1024)         0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'activation_17[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 64, 64, 512)          4719104   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 64, 64, 512)          2048      ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 64, 64, 512)          2359808   ['activation_20[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 64, 64, 512)          2048      ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 128, 128, 256)        524544    ['activation_21[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 128, 128, 512)        0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 128, 128, 256)        1179904   ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 128, 128, 256)        1024      ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 128, 128, 256)        590080    ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 128, 128, 256)        1024      ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 256, 256, 128)        131200    ['activation_23[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 256, 256, 256)        0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 256, 256, 128)        295040    ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 256, 256, 128)        512       ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 256, 256, 128)        147584    ['activation_24[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 256, 256, 128)        512       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2D  (None, 512, 512, 64)         32832     ['activation_25[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 512, 512, 128)        0         ['conv2d_transpose_4[0][0]',  \n",
      " )                                                                   'activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 512, 512, 64)         73792     ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 512, 512, 64)         256       ['conv2d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 512, 512, 64)         36928     ['activation_26[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 512, 512, 64)         256       ['conv2d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 512, 512, 20)         1300      ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31056532 (118.47 MB)\n",
      "Trainable params: 31044756 (118.43 MB)\n",
      "Non-trainable params: 11776 (46.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  input_shape = (512, 512, 3)\n",
    "  model = build_unet(input_shape, 20)\n",
    "  model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "l63duuEtgdNC"
   },
   "outputs": [],
   "source": [
    "def load_dataset(data_path, split=0.2):\n",
    "  images = sorted(glob(os.path.join(data_path, \"Training\", \"Images\", \"*\")))[0:10000]\n",
    "  masks = sorted(glob(os.path.join(data_path, \"Training\", \"Categories\", \"*\")))[0:10000]\n",
    "\n",
    "  #print(f\"Images : {len(images)}, Masks :{len(masks)}\")\n",
    "  #print(images[0])\n",
    "  #print(masks[0])\n",
    "\n",
    "  split_size = int(len(images) * split)\n",
    "    \n",
    "  X_train, X_val = train_test_split(images, test_size=split_size, random_state=42)\n",
    "  y_train, y_val = train_test_split(masks, test_size=split_size, random_state=42)\n",
    "\n",
    "  X_train, X_test = train_test_split(X_train, test_size=split_size, random_state=42)\n",
    "  y_train, y_test = train_test_split(y_train, test_size=split_size, random_state=42)\n",
    "\n",
    "  return (X_train, y_train), (X_val, y_val), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PnmG3VZci2_a"
   },
   "outputs": [],
   "source": [
    "def get_colormap(path):\n",
    "  mat_path = os.path.join(path, \"human_colormap.mat\")\n",
    "  color_map = scipy.io.loadmat(mat_path)[\"colormap\"]\n",
    "  #print(color_map)\n",
    "  #print(len(color_map))\n",
    "  color_map = color_map * 256\n",
    "  color_map = color_map.astype(np.uint8)\n",
    "  color_map = [[c[2], c[1], c[0]] for c in color_map]\n",
    "  #print(color_map)\n",
    "  classes = [\n",
    "      \"Backgraoun\",\n",
    "      \"Hat\",\n",
    "      \"Hair\",\n",
    "      \"Glove\",\n",
    "      \"Sunglasses\",\n",
    "      \"Dress\",\n",
    "      \"Coat\",\n",
    "      \"Socks\",\n",
    "      \"Pants\",\n",
    "      \"Torso-skon\",\n",
    "      \"Scarf\",\n",
    "      \"Shirt\",\n",
    "      \"Faca\",\n",
    "      \"Left-arm\",\n",
    "      \"Right-arm\",\n",
    "      \"Left-show\",\n",
    "      \"Right-show\"\n",
    "  ]\n",
    "\n",
    "  return classes, color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "79JH1JhHgdP6"
   },
   "outputs": [],
   "source": [
    "def read_images(path):\n",
    "  #path = tf.io.read_file(path)\n",
    "  #path = path.decode()\n",
    "  x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "  x = cv2.resize(x , (IMG_W, IMG_H))\n",
    "  x = x / 255.0\n",
    "  x = x.astype(np.float32)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uQQvcvrMgdSy"
   },
   "outputs": [],
   "source": [
    "def read_mask(path):\n",
    "  #path = tf.io.read_file(path)\n",
    "  #path = path.decode()\n",
    "  x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "  x = cv2.resize(x , (IMG_W, IMG_H))\n",
    "\n",
    "  outputs = []\n",
    "  for i, color in enumerate(COLOR_MAP):\n",
    "    cmap = np.all(np.equal(x, color), axis=-1)\n",
    "    #print(cmap)\n",
    "    cv2.imwrite(f\"cmap_{i}.png\", cmap * 255)\n",
    "    outputs.append(cmap)\n",
    "\n",
    "  outputs = np.stack(outputs, axis=-1)\n",
    "  outputs = outputs.astype(np.uint8)\n",
    "\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LRXbZOdHgdVa"
   },
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "  def _parse(x, y):\n",
    "    x = x.decode()\n",
    "    y = y.decode()\n",
    "    x = read_images(x)\n",
    "    y = read_mask(y)\n",
    "    return x, y\n",
    "\n",
    "  image, mask = tf.numpy_function(_parse, [x, y], [tf.float32, tf.uint8])\n",
    "  image.set_shape([IMG_H, IMG_W, 3])\n",
    "  mask.set_shape([IMG_H, IMG_W, NUM_CLASSES])\n",
    "  return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PKypg-RxgdYK"
   },
   "outputs": [],
   "source": [
    "def tf_dataset(X, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.shuffle(buffer_size=5000)\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(10)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "emgWB5f5evKz",
    "outputId": "78f1f8a8-d3e1-40cc-f837-84c34c982447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 0s - loss: 1.2802\n",
      "Epoch 1: val_loss improved from inf to 1.11949, saving model to E:/files\\Segmentation_100epochs_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamid\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 14792s 5s/step - loss: 1.2802 - val_loss: 1.1195 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "path = \"/content/drive/MyDrive/Data\"\n",
    "\n",
    "dataset_path = r\"E:\\python\\segmentation\\Computer Vision\\UNET\\data\\instance-level-human-parsing\\instance-level_human_parsing\\instance-level_human_parsing\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  np.random.seed(42)\n",
    "  tf.random.set_seed(42)\n",
    "\n",
    "  create_dir(dataset_path + \"/files\")\n",
    "\n",
    "  IMG_H = 320\n",
    "  IMG_W = 416\n",
    "  NUM_CLASSES = 20\n",
    "\n",
    "  input_shape = (IMG_H, IMG_W, 3)\n",
    "\n",
    "  batch_size = 2\n",
    "  learning_rate = 1e-4\n",
    "  num_epochs = 1\n",
    "\n",
    "  #dataset_path = \"/content/drive/MyDrive/Data/instance-level-human-parsing/instance-level_human_parsing/instance-level_human_parsing\"\n",
    "\n",
    "  model_path = os.path.join(dataset_path, \"/files\", \"Segmentation_100epochs_model.h5\")\n",
    "\n",
    "  csv_path = os.path.join(dataset_path, \"/files\", \"Segmentation_csv_log.csv\")\n",
    "\n",
    "  (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_dataset(dataset_path)\n",
    "\n",
    "  #print(f\"Train: {len(X_train)} / {len(y_train)} - Valid : {len(X_val)} / {len(y_val)} - Test : {len(X_test)} / {len(y_test)}\")\n",
    "\n",
    "  CLASSES, COLOR_MAP = get_colormap(dataset_path)\n",
    "\n",
    "  train_dataset = tf_dataset(X_train, y_train, batch=batch_size)\n",
    "  val_dataset = tf_dataset(X_val, y_val, batch=batch_size)\n",
    "\n",
    "  model = build_unet(input_shape, NUM_CLASSES)\n",
    "  model.compile(\n",
    "      loss=\"categorical_crossentropy\",\n",
    "      optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "  )\n",
    "  #model.summary()\n",
    "\n",
    "  callbacks = [\n",
    "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "    CSVLogger(csv_path, append=True),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "  model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Instance_level_human_Segmentation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oxqEBs4Zxt7m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gratscale_to_rgb(y_pred, CLASSES, colormap):\n",
    "    h, w, _ = y_pred.shape\n",
    "    y_pred = y_pred.astype(np.int32)\n",
    "\n",
    "    output = []\n",
    "    for i, pixel in enumerate(y_pred.flatten()):\n",
    "        output.append(colormap[pixel])\n",
    "\n",
    "    output = np.reshape(output, (h, w, 3))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "EOfaIYyaxkEY"
   },
   "outputs": [],
   "source": [
    "def save_results(image, mask, y_pred, save_image_path):\n",
    "  h, w, _ = image.shape\n",
    "  line = np.ones((h, 10, 3)) * 255\n",
    "\n",
    "  y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "  y_pred = gratscale_to_rgb(y_pred, CLASSES, COLOR_MAP)\n",
    "\n",
    "  cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n",
    "  cv2.imwrite(save_image_path, cat_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"E:\\python\\segmentation\\Computer Vision\\UNET\\data\\instance-level-human-parsing\\instance-level_human_parsing\\instance-level_human_parsing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "kUx-jCOQevNs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0004097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:04<00:37,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0010674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:05<00:17,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:06<00:11,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0009686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:06<00:08,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:07<00:06,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:08<00:04,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0003750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:09<00:03,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:10<00:02,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:11<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0004331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"E:\\python\\segmentation\\Computer Vision\\UNET\\data\\instance-level-human-parsing\\instance-level_human_parsing\\instance-level_human_parsing\\files\"\n",
    "saved_model = r\"E:\\python\\segmentation\\Computer Vision\\UNET\\data\"\n",
    "if __name__==\"__main__\":\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    create_dir(data_path + \"/results\")\n",
    "\n",
    "    IMG_H = 320\n",
    "    IMG_W = 416\n",
    "    NUM_CLASSES = 20\n",
    "\n",
    "    #dataset_path = \"/content/drive/MyDrive/Data/instance-level-human-parsing/instance-level_human_parsing\"\n",
    "\n",
    "    model_path= os.path.join(saved_model, \"Instance_level_human_Segmentation.h5\")\n",
    "    model = load_model(model_path, compile=False)\n",
    "\n",
    "    CLASSES, COLOR_MAP = get_colormap(dataset_path)\n",
    "\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_dataset(dataset_path)\n",
    "\n",
    "\n",
    "    #print(f\"Train: {len(X_train)} / {len(y_train)} - Valid : {len(X_val)} / {len(y_val)} - Test : {len(X_test)} / {len(y_test)}\")\n",
    "\n",
    "    X_test = X_test[:10]\n",
    "    y_test = y_test[:10]\n",
    "\n",
    "    score = []\n",
    "    for x, y in tqdm(zip(X_test, y_test), total=len(X_test)):\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        print(name)\n",
    "\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (IMG_W, IMG_H))\n",
    "        image_x = image\n",
    "        image = image / 255.0\n",
    "        #x = x.astype(np.float32)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        mask = cv2.imread(y, cv2.IMREAD_COLOR)\n",
    "        mask = cv2.resize(mask, (IMG_W, IMG_H))\n",
    "\n",
    "        mask_x = mask\n",
    "\n",
    "        onehot_mask = []\n",
    "\n",
    "        for color in COLOR_MAP:\n",
    "            cmap = np.all(np.equal(mask, color), axis=-1)\n",
    "            onehot_mask.append(cmap)\n",
    "\n",
    "        onehot_mask = np.stack(onehot_mask, axis=-1)\n",
    "        onehot_mask = np.argmax(onehot_mask, axis=-1)\n",
    "        onehot_mask = onehot_mask.astype(np.int32)\n",
    "\n",
    "        my_path = r\"E:\\python\\segmentation\\Computer Vision\\UNET\\data\"      \n",
    "\n",
    "        cv2.imwrite(my_path + \"\\\\rgn.png\", mask_x)\n",
    "        #cv2.imwrite(my_path + \"\\\\rgn_mask.png\", onehot_mask * (255/20))\n",
    "\n",
    "        pred = model.predict(image, verbose=0)[0]\n",
    "        #print(pred)\n",
    "        pred = np.argmax(pred, axis=-1)\n",
    "        #print(pred)\n",
    "        pred = pred.astype(np.float32)\n",
    "\n",
    "        #cv2.imwrite(my_path + \"\\\\pred.png\", pred * (255/20))\n",
    "\n",
    "        save_image_path = os.path.join(my_path, f\"{name}.png\")\n",
    "        save_results(image_x, mask, pred, save_image_path)\n",
    "\n",
    "        onehot_mask = onehot_mask.flatten()\n",
    "        pred = pred.flatten()\n",
    "\n",
    "        labels = [i for i in range(NUM_CLASSES)]\n",
    "\n",
    "        f1_value = f1_score(onehot_mask, pred, labels=labels, average=None, zero_division=0)\n",
    "        jac_value = jaccard_score(onehot_mask, pred, labels=labels, average=None, zero_division=0)\n",
    "\n",
    "        #print(f1_value)\n",
    "        score.append([f1_value, jac_value])\n",
    "\n",
    "    score = np.array(score)\n",
    "    score = np.mean(score, axis=0)\n",
    "    print(score.shape)\n",
    "\n",
    "    f = open(data_path + \"\\\\score.csv\", \"w\")\n",
    "    f.write(\"Class\", \"F1\", \"Jaccard\\n\")\n",
    "\n",
    "    l = [\"Class\", \"F1\", \"Jaccard\"]\n",
    "    print(f\"{l[0]:15s} {l[1]:10s} {l[2]:10s}\")\n",
    "    print(\"_\"*35)\n",
    "\n",
    "    for i in range(score.shape[1]):\n",
    "        class_name = CLASSES[1]\n",
    "        f1 = score[0, i]\n",
    "        jac = score[1, i]\n",
    "        dstr = f\"{class_name:15s}: {f1:1.5f} - {jac:1.5f}\"\n",
    "        print(dstr)\n",
    "        f.write(f\"{class_name:15s}, {f1:1.5f}, {jac:1.5f}\\n\")\n",
    "\n",
    "    print(\"_\"*35)\n",
    "    class_mean = np.mean(score, axis=-1)\n",
    "    class_name = \"Mean\"\n",
    "    f1 = class_mean[0]\n",
    "    jac = class_mean[1]\n",
    "    dstr = f\"{class_name:15s}: {f1:1.5f} - {jac:1.5f}\"\n",
    "    print(dstr)\n",
    "    f.write(f\"{class_name:15s}, {f1:1.5f}, {jac:1.5f}\\n\")\n",
    "\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
